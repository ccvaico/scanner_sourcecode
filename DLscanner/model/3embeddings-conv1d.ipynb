{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "1946b16bed1d69b05b9e0526be3e85eb0ff60988"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, concatenate\n",
    "from keras.layers import CuDNNGRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, Conv1D\n",
    "from keras.layers import Add, BatchNormalization, Activation, CuDNNLSTM, Dropout\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import gc\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "# from scikitplot.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv',sep='\\t')\n",
    "#train_df[\"question_text\"] = train_df[\"question_text\"].map(lambda x: clean_text(x))\n",
    "\n",
    "test_df = pd.read_csv('test.csv',sep='\\t')\n",
    "#test_df[\"question_text\"] = test_df[\"question_text\"].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "1936fc4d824465e575e901b2340346a69caa5a26"
   },
   "outputs": [],
   "source": [
    "X_train = train_df[\"question_text\"].fillna(\"na\").values\n",
    "X_test = test_df[\"question_text\"].fillna(\"na\").values\n",
    "y = train_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "7949781451180e5974bd5f173bb2e7c0e49828b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    }
   ],
   "source": [
    "maxlen = 70\n",
    "max_features = 50000\n",
    "embed_size = 300\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train) + list(X_test))\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "x_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print(\"finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "65913ac95c0706c901b0d3aa15e6fa215f2df612"
   },
   "outputs": [],
   "source": [
    "def attention_3d_block(inputs):\n",
    "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "    TIME_STEPS = inputs.shape[1].value\n",
    "    SINGLE_ATTENTION_VECTOR = False\n",
    "    \n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what.\n",
    "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
    "    if SINGLE_ATTENTION_VECTOR:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1))(a)\n",
    "        a = RepeatVector(input_dim)(a)\n",
    "    a_probs = Permute((2, 1))(a)\n",
    "    output_attention_mul = Multiply()([inputs, a_probs])\n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "ac232215680b2392f914f6b47d95d2a31bb692e4"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers\n",
    "\n",
    "class AttLayer(Layer):\n",
    "    def __init__(self, attention_dim):\n",
    "        self.init = initializers.get('normal')\n",
    "        self.supports_masking = True\n",
    "        self.attention_dim = attention_dim\n",
    "        super(AttLayer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = K.variable(self.init((input_shape[-1], self.attention_dim)))\n",
    "        self.b = K.variable(self.init((self.attention_dim, )))\n",
    "        self.u = K.variable(self.init((self.attention_dim, 1)))\n",
    "        self.trainable_weights = [self.W, self.b, self.u]\n",
    "        super(AttLayer, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # size of x :[batch_size, sel_len, attention_dim]\n",
    "        # size of u :[batch_size, attention_dim]\n",
    "        # uit = tanh(xW+b)\n",
    "        uit = K.tanh(K.bias_add(K.dot(x, self.W), self.b))\n",
    "        ait = K.dot(uit, self.u)\n",
    "        ait = K.squeeze(ait, -1)\n",
    "\n",
    "        ait = K.exp(ait)\n",
    "\n",
    "        if mask is not None:\n",
    "            ait *= K.cast(mask, K.floatx())\n",
    "        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        ait = K.expand_dims(ait)\n",
    "        weighted_input = x * ait\n",
    "        output = K.sum(weighted_input, axis=1)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3cf60b4c5435a4ed23dbb425e135b9b71722cae"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values()) # 二维数组 2096016*300\n",
    "print(all_embs.shape[0])\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()  # scalar 均值，标准差\n",
    "print(\"mean=\",emb_mean)\n",
    "embed_size = all_embs.shape[1]  # 300\n",
    "\n",
    "word_index = tokenizer.word_index  # 单词对应的整数编号形成的列表\n",
    "nb_words = min(max_features, len(word_index))  # 只取两者中较小者的单词数量\n",
    "# 结合下面的代码。对于embeddings中没有的单词，使用随机初始化的词向量\n",
    "embedding_matrix_1 = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: \n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix_1[i] = embedding_vector\n",
    "\n",
    "del embeddings_index; gc.collect() # 内存空间清理\n",
    "print(\"finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "adee6a91e1a8bd5b22658975815aa7f131f52c4c"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())  # 999994*300\n",
    "print(all_embs.shape[0])\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix_2 = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix_2[i] = embedding_vector\n",
    "del embeddings_index; gc.collect()\n",
    "print(\"finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e9f3266123faca65c9e52927fe450bf483939f44"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore') if len(o)>100)\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values()) # 1703755*300\n",
    "print(all_embs.shape[0])\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix_3 = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix_3[i] = embedding_vector\n",
    "        \n",
    "del embeddings_index; gc.collect()   \n",
    "print(\"finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a094e7521a7c5937e04e286dfcbd81b55d1f8350"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.concatenate((embedding_matrix_1, embedding_matrix_2, embedding_matrix_3), axis=1)  \n",
    "del embedding_matrix_1, embedding_matrix_2, embedding_matrix_3\n",
    "gc.collect()\n",
    "print(np.shape(embedding_matrix))\n",
    "print(\"finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "97b554c038275c936f310120207fc64e001e669a"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train, y, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "e1157c228e70e7327c8cf98d66610ea8ff1782e1"
   },
   "outputs": [],
   "source": [
    "def model_conv1d():\n",
    "    filters = 128\n",
    "    \n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    embed = Embedding(max_features, embed_size * 3, trainable=False)(inp)\n",
    "    x = embed\n",
    "    \n",
    "    x = Conv1D(filters, 1, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    x = Conv1D(filters, 2, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    x = Conv1D(filters, 3, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    x = Conv1D(filters, 5, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    #x = Flatten()(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    outp = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "bfe657b6cef3d438f81d7b97f3912d4eabbecee5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 70, 900)           45000000  \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 70, 128)           115328    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 70, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 69, 128)           32896     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 69, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 67, 128)           49280     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 67, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 63, 128)           82048     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 63, 128)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 45,296,193\n",
      "Trainable params: 296,193\n",
      "Non-trainable params: 45,000,000\n",
      "_________________________________________________________________\n",
      "Train on 15285 samples, validate on 1699 samples\n",
      "Epoch 1/3\n",
      "15285/15285 [==============================] - 55s 4ms/step - loss: 0.5175 - acc: 0.8290 - val_loss: 0.3783 - val_acc: 0.8982\n",
      "Epoch 2/3\n",
      "15285/15285 [==============================] - 54s 4ms/step - loss: 0.3524 - acc: 0.8924 - val_loss: 0.3350 - val_acc: 0.8982\n",
      "Epoch 3/3\n",
      "15285/15285 [==============================] - 54s 4ms/step - loss: 0.3303 - acc: 0.8924 - val_loss: 0.3063 - val_acc: 0.8982\n"
     ]
    }
   ],
   "source": [
    "MODEL = model_conv1d()\n",
    "MODEL.summary()\n",
    "\n",
    "batch_size = 2048\n",
    "epochs = 3\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3, verbose=1, monitor='val_loss', mode='min')\n",
    "model_checkpoint = ModelCheckpoint('./model_conv1d.model', save_best_only=True, verbose=1, monitor='val_loss', mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.5, patience=3, min_lr=0.0001, verbose=1)\n",
    "\n",
    "hist = MODEL.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), verbose=True)\n",
    "MODEL.save('./model_conv1d.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "bec955217cd7c14c227c5a749296da2d25a6b4e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1699/1699 [==============================] - 2s 1ms/step\n",
      "acc score at threshold 0.1 is 0.8475573866980577\n",
      "F1 score at threshold 0.1 is 0.3056300268096514\n",
      "precision at threshold 0.1 is 0.285\n",
      "recall at threshold 0.1 is 0.32947976878612717\n",
      "acc score at threshold 0.11 is 0.8552089464390819\n",
      "F1 score at threshold 0.11 is 0.31666666666666665\n",
      "precision at threshold 0.11 is 0.3048128342245989\n",
      "recall at threshold 0.11 is 0.32947976878612717\n",
      "acc score at threshold 0.12 is 0.8599175985874044\n",
      "F1 score at threshold 0.12 is 0.32\n",
      "precision at threshold 0.12 is 0.3163841807909605\n",
      "recall at threshold 0.12 is 0.3236994219653179\n",
      "acc score at threshold 0.13 is 0.8669805768098882\n",
      "F1 score at threshold 0.13 is 0.32738095238095233\n",
      "precision at threshold 0.13 is 0.3374233128834356\n",
      "recall at threshold 0.13 is 0.3179190751445087\n",
      "acc score at threshold 0.14 is 0.8681577398469688\n",
      "F1 score at threshold 0.14 is 0.32934131736526945\n",
      "precision at threshold 0.14 is 0.3416149068322981\n",
      "recall at threshold 0.14 is 0.3179190751445087\n",
      "acc score at threshold 0.15 is 0.8693349028840495\n",
      "F1 score at threshold 0.15 is 0.3231707317073171\n",
      "precision at threshold 0.15 is 0.3419354838709677\n",
      "recall at threshold 0.15 is 0.3063583815028902\n",
      "acc score at threshold 0.16 is 0.872277810476751\n",
      "F1 score at threshold 0.16 is 0.32398753894081\n",
      "precision at threshold 0.16 is 0.35135135135135137\n",
      "recall at threshold 0.16 is 0.30057803468208094\n",
      "acc score at threshold 0.17 is 0.8787522071806946\n",
      "F1 score at threshold 0.17 is 0.33116883116883117\n",
      "precision at threshold 0.17 is 0.37777777777777777\n",
      "recall at threshold 0.17 is 0.2947976878612717\n",
      "acc score at threshold 0.18 is 0.8828722778104767\n",
      "F1 score at threshold 0.18 is 0.3017543859649123\n",
      "precision at threshold 0.18 is 0.38392857142857145\n",
      "recall at threshold 0.18 is 0.24855491329479767\n",
      "acc score at threshold 0.19 is 0.8793407886992348\n",
      "F1 score at threshold 0.19 is 0.163265306122449\n",
      "precision at threshold 0.19 is 0.2777777777777778\n",
      "recall at threshold 0.19 is 0.11560693641618497\n",
      "acc score at threshold 0.2 is 0.8899352560329605\n",
      "F1 score at threshold 0.2 is 0.10526315789473684\n",
      "precision at threshold 0.2 is 0.3055555555555556\n",
      "recall at threshold 0.2 is 0.06358381502890173\n",
      "acc score at threshold 0.21 is 0.8987639788110653\n",
      "F1 score at threshold 0.21 is 0.022727272727272724\n",
      "precision at threshold 0.21 is 0.6666666666666666\n",
      "recall at threshold 0.21 is 0.011560693641618497\n",
      "acc score at threshold 0.22 is 0.8987639788110653\n",
      "F1 score at threshold 0.22 is 0.011494252873563216\n",
      "precision at threshold 0.22 is 1.0\n",
      "recall at threshold 0.22 is 0.005780346820809248\n",
      "acc score at threshold 0.23 is 0.898175397292525\n",
      "F1 score at threshold 0.23 is 0.0\n",
      "precision at threshold 0.23 is 0.0\n",
      "recall at threshold 0.23 is 0.0\n",
      "acc score at threshold 0.24 is 0.898175397292525\n",
      "F1 score at threshold 0.24 is 0.0\n",
      "precision at threshold 0.24 is 0.0\n",
      "recall at threshold 0.24 is 0.0\n",
      "acc score at threshold 0.25 is 0.898175397292525\n",
      "F1 score at threshold 0.25 is 0.0\n",
      "precision at threshold 0.25 is 0.0\n",
      "recall at threshold 0.25 is 0.0\n",
      "acc score at threshold 0.26 is 0.898175397292525\n",
      "F1 score at threshold 0.26 is 0.0\n",
      "precision at threshold 0.26 is 0.0\n",
      "recall at threshold 0.26 is 0.0\n",
      "acc score at threshold 0.27 is 0.898175397292525\n",
      "F1 score at threshold 0.27 is 0.0\n",
      "precision at threshold 0.27 is 0.0\n",
      "recall at threshold 0.27 is 0.0\n",
      "acc score at threshold 0.28 is 0.898175397292525\n",
      "F1 score at threshold 0.28 is 0.0\n",
      "precision at threshold 0.28 is 0.0\n",
      "recall at threshold 0.28 is 0.0\n",
      "acc score at threshold 0.29 is 0.898175397292525\n",
      "F1 score at threshold 0.29 is 0.0\n",
      "precision at threshold 0.29 is 0.0\n",
      "recall at threshold 0.29 is 0.0\n",
      "acc score at threshold 0.3 is 0.898175397292525\n",
      "F1 score at threshold 0.3 is 0.0\n",
      "precision at threshold 0.3 is 0.0\n",
      "recall at threshold 0.3 is 0.0\n",
      "acc score at threshold 0.31 is 0.898175397292525\n",
      "F1 score at threshold 0.31 is 0.0\n",
      "precision at threshold 0.31 is 0.0\n",
      "recall at threshold 0.31 is 0.0\n",
      "acc score at threshold 0.32 is 0.898175397292525\n",
      "F1 score at threshold 0.32 is 0.0\n",
      "precision at threshold 0.32 is 0.0\n",
      "recall at threshold 0.32 is 0.0\n",
      "acc score at threshold 0.33 is 0.898175397292525\n",
      "F1 score at threshold 0.33 is 0.0\n",
      "precision at threshold 0.33 is 0.0\n",
      "recall at threshold 0.33 is 0.0\n",
      "acc score at threshold 0.34 is 0.898175397292525\n",
      "F1 score at threshold 0.34 is 0.0\n",
      "precision at threshold 0.34 is 0.0\n",
      "recall at threshold 0.34 is 0.0\n",
      "acc score at threshold 0.35 is 0.898175397292525\n",
      "F1 score at threshold 0.35 is 0.0\n",
      "precision at threshold 0.35 is 0.0\n",
      "recall at threshold 0.35 is 0.0\n",
      "acc score at threshold 0.36 is 0.898175397292525\n",
      "F1 score at threshold 0.36 is 0.0\n",
      "precision at threshold 0.36 is 0.0\n",
      "recall at threshold 0.36 is 0.0\n",
      "acc score at threshold 0.37 is 0.898175397292525\n",
      "F1 score at threshold 0.37 is 0.0\n",
      "precision at threshold 0.37 is 0.0\n",
      "recall at threshold 0.37 is 0.0\n",
      "acc score at threshold 0.38 is 0.898175397292525\n",
      "F1 score at threshold 0.38 is 0.0\n",
      "precision at threshold 0.38 is 0.0\n",
      "recall at threshold 0.38 is 0.0\n",
      "acc score at threshold 0.39 is 0.898175397292525\n",
      "F1 score at threshold 0.39 is 0.0\n",
      "precision at threshold 0.39 is 0.0\n",
      "recall at threshold 0.39 is 0.0\n",
      "acc score at threshold 0.4 is 0.898175397292525\n",
      "F1 score at threshold 0.4 is 0.0\n",
      "precision at threshold 0.4 is 0.0\n",
      "recall at threshold 0.4 is 0.0\n",
      "acc score at threshold 0.41 is 0.898175397292525\n",
      "F1 score at threshold 0.41 is 0.0\n",
      "precision at threshold 0.41 is 0.0\n",
      "recall at threshold 0.41 is 0.0\n",
      "acc score at threshold 0.42 is 0.898175397292525\n",
      "F1 score at threshold 0.42 is 0.0\n",
      "precision at threshold 0.42 is 0.0\n",
      "recall at threshold 0.42 is 0.0\n",
      "acc score at threshold 0.43 is 0.898175397292525\n",
      "F1 score at threshold 0.43 is 0.0\n",
      "precision at threshold 0.43 is 0.0\n",
      "recall at threshold 0.43 is 0.0\n",
      "acc score at threshold 0.44 is 0.898175397292525\n",
      "F1 score at threshold 0.44 is 0.0\n",
      "precision at threshold 0.44 is 0.0\n",
      "recall at threshold 0.44 is 0.0\n",
      "acc score at threshold 0.45 is 0.898175397292525\n",
      "F1 score at threshold 0.45 is 0.0\n",
      "precision at threshold 0.45 is 0.0\n",
      "recall at threshold 0.45 is 0.0\n",
      "acc score at threshold 0.46 is 0.898175397292525\n",
      "F1 score at threshold 0.46 is 0.0\n",
      "precision at threshold 0.46 is 0.0\n",
      "recall at threshold 0.46 is 0.0\n",
      "acc score at threshold 0.47 is 0.898175397292525\n",
      "F1 score at threshold 0.47 is 0.0\n",
      "precision at threshold 0.47 is 0.0\n",
      "recall at threshold 0.47 is 0.0\n",
      "acc score at threshold 0.48 is 0.898175397292525\n",
      "F1 score at threshold 0.48 is 0.0\n",
      "precision at threshold 0.48 is 0.0\n",
      "recall at threshold 0.48 is 0.0\n",
      "acc score at threshold 0.49 is 0.898175397292525\n",
      "F1 score at threshold 0.49 is 0.0\n",
      "precision at threshold 0.49 is 0.0\n",
      "recall at threshold 0.49 is 0.0\n",
      "acc score at threshold 0.5 is 0.898175397292525\n",
      "F1 score at threshold 0.5 is 0.0\n",
      "precision at threshold 0.5 is 0.0\n",
      "recall at threshold 0.5 is 0.0\n",
      "Best threshold:  0.17\n",
      "4246/4246 [==============================] - 6s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_val_y_3 = MODEL.predict([X_val], batch_size=1024, verbose=1)\n",
    "thresholds = []\n",
    "f1_list = list()\n",
    "thre_list = np.arange(0.1, 0.501, 0.01)\n",
    "for thresh in thre_list:\n",
    "    thresh = np.round(thresh, 2)\n",
    "    acc = metrics.accuracy_score(y_val, (pred_val_y_3 > thresh).astype(int))\n",
    "    f1 = metrics.f1_score(y_val, (pred_val_y_3 > thresh).astype(int))\n",
    "    f1_list.append(f1)\n",
    "    pre = metrics.precision_score(y_val, (pred_val_y_3 > thresh).astype(int))\n",
    "    recall = metrics.recall_score(y_val, (pred_val_y_3 > thresh).astype(int))\n",
    "    thresholds.append([thresh, f1])\n",
    "    print(\"acc score at threshold {0} is {1}\".format(thresh, acc))\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, f1))\n",
    "    print(\"precision at threshold {0} is {1}\".format(thresh, pre))\n",
    "    print(\"recall at threshold {0} is {1}\".format(thresh, recall))\n",
    "    \n",
    "thresholds.sort(key=lambda x: x[1], reverse=True)\n",
    "best_thresh_3 = thresholds[0][0]\n",
    "print(\"Best threshold: \", best_thresh_3)\n",
    "\n",
    "# plot_confusion_matrix(y_val, np.array(pd.Series(pred_val_y_3.reshape(-1,)).map(lambda x:1 if x>thre_list[np.argmax(f1_list)] else 0)))\n",
    "\n",
    "y_pred_3 = MODEL.predict(x_test, batch_size=1024, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc2cd299915590ea5204bc8bd465d92b01cd69a4"
   },
   "outputs": [],
   "source": [
    "# pred_val_y = (3*pred_val_y_2 + 4*pred_val_y_4 + 3*pred_val_y_5)/10\n",
    "# pred_val_y = pred_val_y_3\n",
    "\n",
    "# thresholds = []\n",
    "# for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "#     thresh = np.round(thresh, 2)\n",
    "#     res = metrics.f1_score(y_val, (pred_val_y > thresh).astype(int))\n",
    "#     thresholds.append([thresh, res])\n",
    "#     print(\"F1 score at threshold {0} is {1}\".format(thresh, res))\n",
    "    \n",
    "# thresholds.sort(key=lambda x: x[1], reverse=True)\n",
    "# best_thresh = thresholds[0][0]\n",
    "# print(\"Best threshold: \", best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7fa0823092a4a9f7a4e010cf37827e25e459dcbd"
   },
   "outputs": [],
   "source": [
    "# y_pred = (3*y_pred_2 + 4*y_pred_4 + 3*y_pred_5)/10\n",
    "y_pred = y_pred_3\n",
    "y_te = (y_pred[:,0] > best_thresh_3).astype(np.int)\n",
    "\n",
    "submit_df = pd.DataFrame({\"qid\": test_df[\"qid\"], \"prediction\": y_te})\n",
    "submit_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
